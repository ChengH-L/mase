{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use the Transform functionality without CLI\n",
    "\n",
    "This tutorial describes how to use the MASE transform functionality for a pre-trained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import related packages and machop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lch121600/anaconda3/envs/mase/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34mSet logging level to info\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import set_logging_verbosity\n",
    "\n",
    "from chop.passes.graph.interface import save_node_meta_param_interface_pass\n",
    "from chop.passes.graph.analysis import (\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph import (\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.tools.checkpoint_load import load_model\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "set_logging_verbosity(\"info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the dataset \n",
    "\n",
    "Here we use the previously trained jsc dataset in lab 1 as an example, the dataset is configured using the internal `MaseDataModule`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "model_name = \"vgg7\"\n",
    "dataset_name = \"cifar10\"\n",
    "\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the model \n",
    "\n",
    "Here we use the previously trained jsc-tiny model in lab 1 as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mLoaded pytorch lightning checkpoint from /home/lch121600/ADLSlab/mase/mase_output/vgg7_classification_cifar10_2024-02-21/test-accu-0.9332.ckpt\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# üìùÔ∏è change this CHECKPOINT_PATH to the one you trained in Lab1\n",
    "CHECKPOINT_PATH = \"/home/lch121600/ADLSlab/mase/mase_output/vgg7_classification_cifar10_2024-02-21/test-accu-0.9332.ckpt\"\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False)\n",
    "\n",
    "model = load_model(load_name=CHECKPOINT_PATH, load_type=\"pl\", model=model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get a dummy data in\n",
    "With the dataset module and model information, we can grab an input generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the input generator\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "# a demonstration of how to feed an input value to the model\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a MaseGraph\n",
    "We have two forms of passes: transform passes and analysis passes, both of them would require the model to be transferred into a MaseGraph to allow manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'chop.ir.graph.mase_graph.MaseGraph'>\n"
     ]
    }
   ],
   "source": [
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)\n",
    "\n",
    "print(type(mg))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running an Analysis pass\n",
    "Analysis pass DOES NOT change the graph\n",
    "\n",
    "The following analysis passes are essential to prepare the graph for other passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first run a simple graph analysis to understand the structure of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "graph():\n",
      "    %x : torch.Tensor [num_users=1] = placeholder[target=x]\n",
      "    %feature_layers_0 : [num_users=1] = call_module[target=feature_layers.0](args = (%x,), kwargs = {})\n",
      "    %feature_layers_1 : [num_users=1] = call_module[target=feature_layers.1](args = (%feature_layers_0,), kwargs = {})\n",
      "    %feature_layers_2 : [num_users=1] = call_module[target=feature_layers.2](args = (%feature_layers_1,), kwargs = {})\n",
      "    %feature_layers_3 : [num_users=1] = call_module[target=feature_layers.3](args = (%feature_layers_2,), kwargs = {})\n",
      "    %feature_layers_4 : [num_users=1] = call_module[target=feature_layers.4](args = (%feature_layers_3,), kwargs = {})\n",
      "    %feature_layers_5 : [num_users=1] = call_module[target=feature_layers.5](args = (%feature_layers_4,), kwargs = {})\n",
      "    %feature_layers_6 : [num_users=1] = call_module[target=feature_layers.6](args = (%feature_layers_5,), kwargs = {})\n",
      "    %feature_layers_7 : [num_users=1] = call_module[target=feature_layers.7](args = (%feature_layers_6,), kwargs = {})\n",
      "    %feature_layers_8 : [num_users=1] = call_module[target=feature_layers.8](args = (%feature_layers_7,), kwargs = {})\n",
      "    %feature_layers_9 : [num_users=1] = call_module[target=feature_layers.9](args = (%feature_layers_8,), kwargs = {})\n",
      "    %feature_layers_10 : [num_users=1] = call_module[target=feature_layers.10](args = (%feature_layers_9,), kwargs = {})\n",
      "    %feature_layers_11 : [num_users=1] = call_module[target=feature_layers.11](args = (%feature_layers_10,), kwargs = {})\n",
      "    %feature_layers_12 : [num_users=1] = call_module[target=feature_layers.12](args = (%feature_layers_11,), kwargs = {})\n",
      "    %feature_layers_13 : [num_users=1] = call_module[target=feature_layers.13](args = (%feature_layers_12,), kwargs = {})\n",
      "    %feature_layers_14 : [num_users=1] = call_module[target=feature_layers.14](args = (%feature_layers_13,), kwargs = {})\n",
      "    %feature_layers_15 : [num_users=1] = call_module[target=feature_layers.15](args = (%feature_layers_14,), kwargs = {})\n",
      "    %feature_layers_16 : [num_users=1] = call_module[target=feature_layers.16](args = (%feature_layers_15,), kwargs = {})\n",
      "    %feature_layers_17 : [num_users=1] = call_module[target=feature_layers.17](args = (%feature_layers_16,), kwargs = {})\n",
      "    %feature_layers_18 : [num_users=1] = call_module[target=feature_layers.18](args = (%feature_layers_17,), kwargs = {})\n",
      "    %feature_layers_19 : [num_users=1] = call_module[target=feature_layers.19](args = (%feature_layers_18,), kwargs = {})\n",
      "    %feature_layers_20 : [num_users=1] = call_module[target=feature_layers.20](args = (%feature_layers_19,), kwargs = {})\n",
      "    %view : [num_users=1] = call_method[target=view](args = (%feature_layers_20, -1, 8192), kwargs = {})\n",
      "    %classifier_0 : [num_users=1] = call_module[target=classifier.0](args = (%view,), kwargs = {})\n",
      "    %classifier_1 : [num_users=1] = call_module[target=classifier.1](args = (%classifier_0,), kwargs = {})\n",
      "    %classifier_2 : [num_users=1] = call_module[target=classifier.2](args = (%classifier_1,), kwargs = {})\n",
      "    %classifier_3 : [num_users=1] = call_module[target=classifier.3](args = (%classifier_2,), kwargs = {})\n",
      "    %last_layer : [num_users=1] = call_module[target=last_layer](args = (%classifier_3,), kwargs = {})\n",
      "    return last_layerNetwork overview:\n",
      "{'placeholder': 1, 'get_attr': 0, 'call_function': 0, 'call_method': 1, 'call_module': 26, 'output': 1}\n",
      "Layer types:\n",
      "[Conv2d(3, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True), ReLU(inplace=True), Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(128, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True), ReLU(inplace=True), Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(256, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True), ReLU(inplace=True), Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)), BatchNorm2d(512, eps=1e-05, momentum=0.9, affine=True, track_running_stats=True), ReLU(inplace=True), MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False), Linear(in_features=8192, out_features=1024, bias=True), ReLU(inplace=True), Linear(in_features=1024, out_features=1024, bias=True), ReLU(inplace=True), Linear(in_features=1024, out_features=10, bias=True)]\n"
     ]
    }
   ],
   "source": [
    "# report graph is an analysis pass that shows you the detailed information in the graph\n",
    "from chop.passes import report_graph_analysis_pass\n",
    "_ = report_graph_analysis_pass(mg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running another Analysis pass: Profile statistics\n",
    "\n",
    "The pass `profile_statistics_analysis_pass` collects statistics of parameters and activations, and save them to node's metadata.\n",
    "\n",
    "Here is a list of all the supported statistics. Refer to the `__init__` of statistic classes in `chop.passes.analysis.statistical_profiler.stat` to check the args each stat class takes.\n",
    "\n",
    "This is a more complex analysis than the previous pass, and thus it would require you to pass in additional arguments for this pass.\n",
    "\n",
    "### Example: the range of weights & input activations of nodes\n",
    "\n",
    "Say we want to collect the tensor-wise min-max range of the `torch.nn.Linear` nodes' weights & bias, and the channel-wise 97% quantile min-max of the `torch.nn.ReLU` node's input activations. We can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_args = {\n",
    "    \"by\": \"type\",                                                            # collect statistics by node name\n",
    "    \"target_weight_nodes\": [\"linear\"],                                       # collect weight statistics for linear layers\n",
    "    \"target_activation_nodes\": [\"relu\"],                                     # collect activation statistics for relu layers\n",
    "    \"weight_statistics\": {\n",
    "        \"variance_precise\": {\"device\": \"cpu\", \"dims\": \"all\"},                # collect precise variance of the weight\n",
    "    },\n",
    "    \"activation_statistics\": {\n",
    "        \"range_quantile\": {\"device\": \"cpu\", \"dims\": \"all\", \"quantile\": 0.97} # collect 97% quantile of the activation range\n",
    "    },\n",
    "    \"input_generator\": input_generator,                                      # the input generator for feeding data to the model\n",
    "    \"num_samples\": 32,                                                       # feed 32 samples to the model\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `report_node_meta_param_analysis_pass` to inspect the collected statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Profiling weight statistics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 29/29 [00:00<00:00, 2238.20it/s]\n",
      "Profiling act statistics: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 1/1 [00:04<00:00,  4.58s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "quantile() input tensor is too large",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m mg, _ \u001b[38;5;241m=\u001b[39m \u001b[43mprofile_statistics_analysis_pass\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpass_args\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m mg, _ \u001b[38;5;241m=\u001b[39m report_node_meta_param_analysis_pass(mg, {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhich\u001b[39m\u001b[38;5;124m\"\u001b[39m: (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msoftware\u001b[39m\u001b[38;5;124m\"\u001b[39m,)})\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/analysis/statistical_profiler/profile_statistics.py:313\u001b[0m, in \u001b[0;36mprofile_statistics_analysis_pass\u001b[0;34m(graph, pass_args)\u001b[0m\n\u001b[1;32m    305\u001b[0m graph \u001b[38;5;241m=\u001b[39m graph_iterator_profile_weight(graph)\n\u001b[1;32m    307\u001b[0m graph \u001b[38;5;241m=\u001b[39m graph_iterator_profile_act(\n\u001b[1;32m    308\u001b[0m     graph,\n\u001b[1;32m    309\u001b[0m     input_generator\u001b[38;5;241m=\u001b[39mpass_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput_generator\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    310\u001b[0m     num_samples\u001b[38;5;241m=\u001b[39mpass_args[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_samples\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    311\u001b[0m )\n\u001b[0;32m--> 313\u001b[0m graph \u001b[38;5;241m=\u001b[39m \u001b[43mgraph_iterator_compute_and_unregister_stats\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m graph, {}\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/analysis/statistical_profiler/profile_statistics.py:269\u001b[0m, in \u001b[0;36mgraph_iterator_compute_and_unregister_stats\u001b[0;34m(graph)\u001b[0m\n\u001b[1;32m    267\u001b[0m     stat \u001b[38;5;241m=\u001b[39m s_meta[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstat\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stat, (WeightStatCollection, ActStatCollection)):\n\u001b[0;32m--> 269\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mstat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m         set_meta_arg_stat(node, entry, result)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;66;03m# for entry, s_meta in (\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;66;03m#     node.meta[\"mase\"].parameters[\"software\"][\"results\"].items()\u001b[39;00m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;66;03m# ):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[38;5;66;03m#         result = stat.compute()\u001b[39;00m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;66;03m#         set_meta_result_stat(node, entry, result)\u001b[39;00m\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/analysis/statistical_profiler/profile_statistics.py:38\u001b[0m, in \u001b[0;36mActStatCollection.compute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     36\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m stat \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstats:\n\u001b[0;32m---> 38\u001b[0m     results\u001b[38;5;241m.\u001b[39mupdate(\u001b[43mstat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexport\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m results\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/analysis/statistical_profiler/stat.py:53\u001b[0m, in \u001b[0;36m_StatBase.export\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexport\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m]]:\n\u001b[1;32m     48\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    Export the stat to a dict of dict of lists.\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m    This method calls compute() and converts the results to lists, which is more friendly to toml serialization.\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m     55\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname: {\n\u001b[1;32m     56\u001b[0m             k: v\u001b[38;5;241m.\u001b[39mtolist() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(v, (Tensor)) \u001b[38;5;28;01melse\u001b[39;00m v\n\u001b[1;32m     57\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m results\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m     58\u001b[0m         }\n\u001b[1;32m     59\u001b[0m     }\n",
      "File \u001b[0;32m~/anaconda3/envs/mase/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mase/machop/chop/passes/graph/analysis/statistical_profiler/stat.py:495\u001b[0m, in \u001b[0;36mRangeQuantile.compute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    493\u001b[0m         d_range \u001b[38;5;241m=\u001b[39m maximum \u001b[38;5;241m-\u001b[39m minimum\n\u001b[1;32m    494\u001b[0m \u001b[38;5;28;01mcase\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 495\u001b[0m     minimum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquantile\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    496\u001b[0m     maximum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mquantile(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquantile)\n\u001b[1;32m    497\u001b[0m     d_range \u001b[38;5;241m=\u001b[39m maximum \u001b[38;5;241m-\u001b[39m minimum\n",
      "\u001b[0;31mRuntimeError\u001b[0m: quantile() input tensor is too large"
     ]
    }
   ],
   "source": [
    "mg, _ = profile_statistics_analysis_pass(mg, pass_args)\n",
    "mg, _ = report_node_meta_param_analysis_pass(mg, {\"which\": (\"software\",)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running a Transform pass: Quantisation\n",
    "\n",
    "As its name suggests, the transform pass would modify the `MaseGraph`.\n",
    "Similar to the previous analysis pass example, we would need to first declare the configuration for the pass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pass_args = {\n",
    "\"by\": \"type\",\n",
    "\"default\": {\"config\": {\"name\": None}},\n",
    "\"conv2d\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then proceed to apply the transformation, in this case, we kept the original graph on purpose, so that we can print a `diff`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mINFO    \u001b[0m \u001b[34mQuantized graph histogram:\u001b[0m\n",
      "\u001b[32mINFO    \u001b[0m \u001b[34m\n",
      "| Original type   | OP           |   Total |   Changed |   Unchanged |\n",
      "|-----------------+--------------+---------+-----------+-------------|\n",
      "| BatchNorm2d     | batch_norm2d |       6 |         0 |           6 |\n",
      "| Conv2d          | conv2d       |       6 |         6 |           0 |\n",
      "| Linear          | linear       |       3 |         3 |           0 |\n",
      "| MaxPool2d       | max_pool2d   |       3 |         0 |           3 |\n",
      "| ReLU            | relu         |       8 |         0 |           8 |\n",
      "| output          | output       |       1 |         0 |           1 |\n",
      "| view            | view         |       1 |         0 |           1 |\n",
      "| x               | placeholder  |       1 |         0 |           1 |\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from chop.passes.graph.transforms import (\n",
    "    quantize_transform_pass,\n",
    "    summarize_quantization_analysis_pass,\n",
    ")\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "\n",
    "ori_mg = MaseGraph(model=model)\n",
    "ori_mg, _ = init_metadata_analysis_pass(ori_mg, None)\n",
    "ori_mg, _ = add_common_metadata_analysis_pass(ori_mg, {\"dummy_in\": dummy_in})\n",
    "\n",
    "mg, _ = quantize_transform_pass(mg, pass_args)\n",
    "summarize_quantization_analysis_pass(ori_mg, mg, save_dir=\"quantize_summary\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average bits for w: 32.0\n",
      "Average bits for w: 12.0\n"
     ]
    }
   ],
   "source": [
    "##6.\n",
    "from chop.passes.graph.analysis.quantization.calculate_avg_bits import calculate_avg_bits_mg_analysis_pass\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "ori_mg = MaseGraph(model=model)\n",
    "ori_mg, _ = init_metadata_analysis_pass(ori_mg, None)\n",
    "ori_mg, _ = add_common_metadata_analysis_pass(ori_mg, {\"dummy_in\": dummy_in})\n",
    "\n",
    "\n",
    "result_graph, analysis_results = calculate_avg_bits_mg_analysis_pass(ori_mg, {})\n",
    "print(\"Average bits for w:\", analysis_results[\"w_avg_bit\"])\n",
    "\n",
    "result_graph, analysis_results = calculate_avg_bits_mg_analysis_pass(mg, pass_args)\n",
    "print(\"Average bits for w:\", analysis_results[\"w_avg_bit\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original graph\n",
      "Operation: linear, Node: seq_blocks_2\n",
      "  Weight Shape: [5, 16]\n",
      "  Precision: [32] bits\n",
      "  Weight : Parameter containing:\n",
      "tensor([[-1.3568e-01,  2.9449e-01, -1.0031e-01, -7.3900e-02,  7.2525e-03,\n",
      "          1.5064e-01,  1.0131e-01,  3.3722e-01,  7.9390e-02,  2.4162e-01,\n",
      "          1.0258e-01,  1.1960e-01, -6.6988e-02, -3.4505e-03,  3.3916e-02,\n",
      "          1.9480e-01],\n",
      "        [ 2.6927e-01, -1.6469e-02, -3.3183e-01, -2.1290e-01, -5.3244e-02,\n",
      "          1.0379e-01,  9.6389e-04,  2.5864e-01,  1.1306e-02,  7.5775e-02,\n",
      "          2.7047e-01, -1.0713e-01, -1.1219e-01,  5.2345e-02, -2.6532e-01,\n",
      "          5.1085e-02],\n",
      "        [-2.1783e-02,  4.3771e-02, -1.7906e-01, -4.0549e-01, -1.8858e-01,\n",
      "          9.8225e-02,  1.2975e-01,  5.0967e-02,  2.7775e-02, -1.6300e-01,\n",
      "          7.3984e-02, -2.4694e-01, -2.3154e-01, -1.8903e-01,  1.5337e-01,\n",
      "         -1.6191e-02],\n",
      "        [-1.1567e-01, -7.7866e-02,  7.1458e-02,  1.5914e-01,  3.0221e-02,\n",
      "         -3.9674e-02,  1.4878e-01, -1.8178e-01,  2.9177e-02, -2.4090e-01,\n",
      "         -2.2247e-01, -1.7197e-01,  7.3240e-02,  5.3948e-02, -2.2460e-01,\n",
      "         -6.3201e-05],\n",
      "        [-2.7511e-02,  5.2719e-02,  1.6840e-01,  2.1862e-01,  3.0843e-01,\n",
      "          3.9755e-01, -2.2397e-01, -7.0843e-02,  7.2827e-02,  9.8120e-02,\n",
      "          7.6374e-02,  1.1672e-01, -5.8789e-02, -2.4259e-01,  1.6333e-01,\n",
      "         -8.7996e-02]], requires_grad=True)\n",
      "\n",
      "modified grapgh\n",
      "Operation: linear, Node: seq_blocks_2\n",
      "  Weight Shape: [5, 16]\n",
      "  Precision: [8, 4] bits\n",
      "  Weight : Parameter containing:\n",
      "tensor([[-1.3568e-01,  2.9449e-01, -1.0031e-01, -7.3900e-02,  7.2525e-03,\n",
      "          1.5064e-01,  1.0131e-01,  3.3722e-01,  7.9390e-02,  2.4162e-01,\n",
      "          1.0258e-01,  1.1960e-01, -6.6988e-02, -3.4505e-03,  3.3916e-02,\n",
      "          1.9480e-01],\n",
      "        [ 2.6927e-01, -1.6469e-02, -3.3183e-01, -2.1290e-01, -5.3244e-02,\n",
      "          1.0379e-01,  9.6389e-04,  2.5864e-01,  1.1306e-02,  7.5775e-02,\n",
      "          2.7047e-01, -1.0713e-01, -1.1219e-01,  5.2345e-02, -2.6532e-01,\n",
      "          5.1085e-02],\n",
      "        [-2.1783e-02,  4.3771e-02, -1.7906e-01, -4.0549e-01, -1.8858e-01,\n",
      "          9.8225e-02,  1.2975e-01,  5.0967e-02,  2.7775e-02, -1.6300e-01,\n",
      "          7.3984e-02, -2.4694e-01, -2.3154e-01, -1.8903e-01,  1.5337e-01,\n",
      "         -1.6191e-02],\n",
      "        [-1.1567e-01, -7.7866e-02,  7.1458e-02,  1.5914e-01,  3.0221e-02,\n",
      "         -3.9674e-02,  1.4878e-01, -1.8178e-01,  2.9177e-02, -2.4090e-01,\n",
      "         -2.2247e-01, -1.7197e-01,  7.3240e-02,  5.3948e-02, -2.2460e-01,\n",
      "         -6.3201e-05],\n",
      "        [-2.7511e-02,  5.2719e-02,  1.6840e-01,  2.1862e-01,  3.0843e-01,\n",
      "          3.9755e-01, -2.2397e-01, -7.0843e-02,  7.2827e-02,  9.8120e-02,\n",
      "          7.6374e-02,  1.1672e-01, -5.8789e-02, -2.4259e-01,  1.6333e-01,\n",
      "         -8.7996e-02]], requires_grad=True)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from chop.passes.graph.analysis.quantization.calculate_avg_bits import calculate_avg_bits_mg_analysis_pass\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "\n",
    "def calculate_bits_mg_analysis_pass(graph, pass_args: dict):\n",
    "\n",
    "    \n",
    "\n",
    "    for node in graph.fx_graph.nodes:\n",
    "        mase_meta = node.meta[\"mase\"].parameters\n",
    "        mase_op = mase_meta[\"common\"][\"mase_op\"]\n",
    "        mase_type = mase_meta[\"common\"][\"mase_type\"]\n",
    "\n",
    "    \n",
    "        if mase_type in [\"module\", \"module_related_func\"]:\n",
    "           if mase_op in [\"linear\", \"conv2d\", \"conv1d\"]:\n",
    "              w_meta = mase_meta[\"common\"][\"args\"][\"weight\"]\n",
    "              # Display the weight metadata\n",
    "              print(f\"Operation: {mase_op}, Node: {node.name}\")\n",
    "              print(f\"  Weight Shape: {w_meta['shape']}\")\n",
    "              print(f\"  Precision: {w_meta['precision']} bits\")\n",
    "              print(f\"  Weight : {w_meta['value']}\")\n",
    "              print()  # Just for better readability between nodes\n",
    "\n",
    "print (\"original graph\")\n",
    "calculate_bits_mg_analysis_pass(ori_mg, {})\n",
    "    \n",
    "\n",
    "print(\"modified grapgh\")\n",
    "calculate_bits_mg_analysis_pass(mg, pass_args)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38400\n",
      "48000\n",
      "508800.0\n",
      "528000.0\n",
      "2371200.0\n",
      "2409600.0\n",
      "4252800.0\n",
      "4329600.0\n",
      "4348800.0\n",
      "4809600.0\n",
      "4848000.0\n",
      "4857600.0\n",
      "4929600.0\n",
      "4932600.0\n",
      "4932600.0\n"
     ]
    }
   ],
   "source": [
    "#7.\n",
    "from chop.passes.graph.analysis.flop_estimator.calculator.calc_modules import calculate_modules\n",
    "from chop.passes.graph.analysis.quantization.calculate_avg_bits import calculate_avg_bits_mg_analysis_pass\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "\n",
    "def FLOP_count(graph, pass_args: dict):\n",
    "    flop = 0\n",
    "    for node in graph.fx_graph.nodes:\n",
    "        mase_meta = node.meta[\"mase\"].parameters\n",
    "        mase_op = mase_meta[\"common\"][\"mase_op\"]\n",
    "        mase_type = mase_meta[\"common\"][\"mase_type\"]\n",
    "        if mase_type in [\"module\", \"module_related_func\"]:\n",
    "             m = mase_meta[\"common\"][\"args\"][\"data_in_0\"][\"type\"]\n",
    "             if m in [\"float\"]:\n",
    "            #    n_modual = mase_meta[\"common\"][\"mase_type\"][\"module\"]\n",
    "               in_data = mase_meta[\"common\"][\"args\"][\"data_in_0\"][\"value\"]\n",
    "               out_data = mase_meta[\"common\"][\"results\"][\"data_out_0\"][\"value\"]\n",
    "            \n",
    "               result = calculate_modules(node.meta[\"mase\"].module, [in_data], [out_data])\n",
    "               if (result != None):\n",
    "                 flop += (result[\"computations\"] +result[\"backward_computations\"])\n",
    "\n",
    "               print(flop)\n",
    "\n",
    "    return flop\n",
    "\n",
    "\n",
    "\n",
    "           \n",
    "\n",
    "f = FLOP_count(ori_mg, pass_args)\n",
    "print (f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.\n",
    "\n",
    "A sequential representation of the operations in your MyModule's forward method. It starts with the input placeholder, adds the learnable parameter param, passes the result through a linear layer, and finally applies a clamping operation. Each node in the graph corresponds to an operation or method call in your PyTorch model, providing a clear and detailed overview of the computational steps involved.\n",
    "\n",
    "\n",
    "2. \n",
    "\n",
    "profile_statistics_analysis_pass:\n",
    "\n",
    "This function is likely used for profiling a neural network model.\n",
    "It analyzes the model graph (mg in your code) to gather statistics about the model's layers and operations.\n",
    "These statistics might include information such as the number of parameters in each layer, memory usage, computational cost, and execution time.\n",
    "The pass_args argument could be for providing additional options or configurations for the profiling.\n",
    "After execution, this function updates the model graph with profiling information which can be used for optimization, debugging, or understanding the model's performance characteristics.\n",
    "\n",
    "report_node_meta_param_analysis_pass:\n",
    "\n",
    "This function appears to generate a report based on the analysis of meta-parameters of nodes in the model graph.\n",
    "The mg parameter would be the model graph, similar to the previous function.\n",
    "The {\"which\": (\"software\",)} argument suggests that this function is filtering or focusing the analysis on certain types of nodes or aspects of the model, possibly those that are software-related. This might mean analyzing aspects like software layers, configurations, or parameters as opposed to hardware-related aspects.\n",
    "The purpose of this function could be to provide insights into specific parts of the model, such as how certain parameters are set or how different layers are configured, which can be crucial for fine-tuning the model or understanding its behavior.\n",
    "\n",
    "3.\n",
    "\n",
    "pass_arg change the liner layer (converted ), the linear layers should be quantized using integer quantization. An 8-bit width is specified for the data with 4 bits used for the fractional part. This means that the values will be represented using fixed-point notation, allowing for 4 bits of precision after the decimal point."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
