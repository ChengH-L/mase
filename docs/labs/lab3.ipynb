{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lch121600/anaconda3/envs/mase/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import logging\n",
    "import os\n",
    "from pathlib import Path\n",
    "from pprint import pprint as pp\n",
    "\n",
    "# figure out the correct path\n",
    "machop_path = Path(\".\").resolve().parent.parent /\"machop\"\n",
    "assert machop_path.exists(), \"Failed to find machop at: {}\".format(machop_path)\n",
    "sys.path.append(str(machop_path))\n",
    "\n",
    "from chop.dataset import MaseDataModule, get_dataset_info\n",
    "from chop.tools.logger import get_logger\n",
    "\n",
    "from chop.passes.graph.analysis import (\n",
    "    report_node_meta_param_analysis_pass,\n",
    "    profile_statistics_analysis_pass,\n",
    ")\n",
    "from chop.passes.graph import (\n",
    "    add_common_metadata_analysis_pass,\n",
    "    init_metadata_analysis_pass,\n",
    "    add_software_metadata_analysis_pass,\n",
    ")\n",
    "from chop.tools.get_input import InputGenerator\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "from chop.models import get_model_info, get_model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "logger = get_logger(\"chop\")\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "batch_size = 8\n",
    "model_name = \"jsc-tiny\"\n",
    "dataset_name = \"jsc\"\n",
    "\n",
    "\n",
    "data_module = MaseDataModule(\n",
    "    name=dataset_name,\n",
    "    batch_size=batch_size,\n",
    "    model_name=model_name,\n",
    "    num_workers=0,\n",
    "    # custom_dataset_cache_path=\"../../chop/dataset\"\n",
    ")\n",
    "data_module.prepare_data()\n",
    "data_module.setup()\n",
    "\n",
    "model_info = get_model_info(model_name)\n",
    "model = get_model(\n",
    "    model_name,\n",
    "    task=\"cls\",\n",
    "    dataset_info=data_module.dataset_info,\n",
    "    pretrained=False,\n",
    "    checkpoint = None)\n",
    "\n",
    "input_generator = InputGenerator(\n",
    "    data_module=data_module,\n",
    "    model_info=model_info,\n",
    "    task=\"cls\",\n",
    "    which_dataloader=\"train\",\n",
    ")\n",
    "\n",
    "dummy_in = next(iter(input_generator))\n",
    "_ = model(**dummy_in)\n",
    "\n",
    "# generate the mase graph and initialize node metadata\n",
    "mg = MaseGraph(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a Search Space\n",
    "\n",
    "\n",
    "pass_args = {\n",
    "\"by\": \"type\",\n",
    "\"default\": {\"config\": {\"name\": None}},\n",
    "\"linear\": {\n",
    "        \"config\": {\n",
    "            \"name\": \"integer\",\n",
    "            # data\n",
    "            \"data_in_width\": 8,\n",
    "            \"data_in_frac_width\": 4,\n",
    "            # weight\n",
    "            \"weight_width\": 8,\n",
    "            \"weight_frac_width\": 4,\n",
    "            # bias\n",
    "            \"bias_width\": 8,\n",
    "            \"bias_frac_width\": 4,\n",
    "        }\n",
    "},}\n",
    "\n",
    "import copy\n",
    "# build a search space\n",
    "data_in_frac_widths = [(16, 8), (8, 6), (8, 4), (4, 2)]\n",
    "w_in_frac_widths = [(16, 8), (8, 6), (8, 4), (4, 2)]\n",
    "search_spaces = []\n",
    "for d_config in data_in_frac_widths:\n",
    "    for w_config in w_in_frac_widths:\n",
    "        pass_args['linear']['config']['data_in_width'] = d_config[0]\n",
    "        pass_args['linear']['config']['data_in_frac_width'] = d_config[1]\n",
    "        pass_args['linear']['config']['weight_width'] = w_config[0]\n",
    "        pass_args['linear']['config']['weight_frac_width'] = w_config[1]\n",
    "        # dict.copy() and dict(dict) only perform shallow copies\n",
    "        # in fact, only primitive data types in python are doing implicit copy when a = b happens\n",
    "        search_spaces.append(copy.deepcopy(pass_args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3004, Loss: 1.566, Latency: 0.00023865699768066406 seconds, Model Size: 0.0034532546997070312 MB\n",
      "Accuracy: 0.2512, Loss: 1.555, Latency: 0.00022520337785993303 seconds, Model Size: 0.0034532546997070312 MB\n",
      "Accuracy: 0.1976, Loss: 1.626, Latency: 0.00021123886108398438 seconds, Model Size: 0.0034532546997070312 MB\n",
      "Accuracy: 0.07143, Loss: 1.622, Latency: 0.00021542821611676897 seconds, Model Size: 0.0034532546997070312 MB\n",
      "Accuracy: 0.2024, Loss: 1.554, Latency: 0.00021682466779436384 seconds, Model Size: 0.0034532546997070312 MB\n",
      "Accuracy: 0.306, Loss: 1.524, Latency: 0.00022833687918526785 seconds, Model Size: 0.0034532546997070312 MB\n",
      "Accuracy: 0.1143, Loss: 1.633, Latency: 0.00021420206342424666 seconds, Model Size: 0.0034532546997070312 MB\n",
      "Accuracy: 0.2333, Loss: 1.551, Latency: 0.00020994458879743303 seconds, Model Size: 0.0034532546997070312 MB\n",
      "Accuracy: 0.2315, Loss: 1.559, Latency: 0.0002005781446184431 seconds, Model Size: 0.0034532546997070312 MB\n",
      "Accuracy: 0.2738, Loss: 1.531, Latency: 0.00019325528826032366 seconds, Model Size: 0.0034532546997070312 MB\n",
      "Accuracy: 0.09524, Loss: 1.6, Latency: 0.0002029282706124442 seconds, Model Size: 0.0034532546997070312 MB\n",
      "Accuracy: 0.3968, Loss: 1.551, Latency: 0.00020599365234375 seconds, Model Size: 0.0034532546997070312 MB\n",
      "Accuracy: 0.2536, Loss: 1.567, Latency: 0.00019689968654087612 seconds, Model Size: 0.0034532546997070312 MB\n",
      "Accuracy: 0.2119, Loss: 1.59, Latency: 0.0002951622009277344 seconds, Model Size: 0.0034532546997070312 MB\n",
      "Accuracy: 0.2702, Loss: 1.583, Latency: 0.00019540105547223772 seconds, Model Size: 0.0034532546997070312 MB\n",
      "Accuracy: 0.3304, Loss: 1.579, Latency: 0.00020762852260044644 seconds, Model Size: 0.0034532546997070312 MB\n"
     ]
    }
   ],
   "source": [
    "#Defining a search strategy and a runner\n",
    "# grid search\n",
    "\n",
    "\n",
    "import torch\n",
    "import time\n",
    "from torchmetrics.classification import MulticlassAccuracy\n",
    "from chop.passes.graph.transforms import (\n",
    "    quantize_transform_pass,\n",
    "    summarize_quantization_analysis_pass,\n",
    ")\n",
    "from chop.ir.graph.mase_graph import MaseGraph\n",
    "\n",
    "mg, _ = init_metadata_analysis_pass(mg, None)\n",
    "mg, _ = add_common_metadata_analysis_pass(mg, {\"dummy_in\": dummy_in})\n",
    "mg, _ = add_software_metadata_analysis_pass(mg, None)\n",
    "\n",
    "metric = MulticlassAccuracy(num_classes=5)\n",
    "num_batchs = 5\n",
    "# This first loop is basically our search strategy,\n",
    "# in this case, it is a simple brute force search\n",
    "\n",
    "recorded_accs = []\n",
    "for i, config in enumerate(search_spaces):\n",
    "    mg, _ = quantize_transform_pass(mg, config)\n",
    "    j = 0\n",
    "    \n",
    "\n",
    "    # Measure model size after quantization\n",
    "    temp_model_path = \"temp_model.pth\"\n",
    "    torch.save(mg.model.state_dict(), temp_model_path)\n",
    "    model_size = os.path.getsize(temp_model_path) / (1024 * 1024)  # Size in MB\n",
    "    os.remove(temp_model_path)  # Clean up the temporary file\n",
    "\n",
    "    # this is the inner loop, where we also call it as a runner.\n",
    "    acc_avg, loss_avg = 0, 0\n",
    "    accs, losses = [], []\n",
    "    latencies = []\n",
    "    for inputs in data_module.train_dataloader():\n",
    "        xs, ys = inputs\n",
    "\n",
    "        #latency\n",
    "        start_time = time.time()\n",
    "        preds = mg.model(xs)\n",
    "        end_time = time.time()\n",
    "        latencies.append(end_time - start_time)\n",
    "        #accuracy; loss\n",
    "        loss = torch.nn.functional.cross_entropy(preds, ys)\n",
    "        acc = metric(preds, ys)\n",
    "        accs.append(acc)\n",
    "        losses.append(loss)\n",
    "        if j > num_batchs:\n",
    "            break\n",
    "        j += 1\n",
    "\n",
    "        \n",
    "    acc_avg = sum(accs) / len(accs)\n",
    "    loss_avg = sum(losses) / len(losses)\n",
    "    latency_avg = sum(latencies) / len(latencies)\n",
    "    recorded_accs.append(acc_avg)\n",
    "    \n",
    "    #print(acc_avg, loss_avg)\n",
    "    #print(loss_avg)\n",
    "    #print((end_time - start_time))\n",
    "\n",
    "    print(f\"Accuracy: {acc_avg:.4g}, Loss: {loss_avg:.4g}, Latency: {latency_avg} seconds, Model Size: {model_size} MB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
